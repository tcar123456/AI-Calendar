# èªéŸ³è™•ç†å„ªåŒ–æŒ‡å—

## ğŸ“Š ç•¶å‰æµç¨‹æ™‚é–“åˆ†æ

```
ç”¨æˆ¶éŒ„éŸ³çµæŸ
   â†“ (~2-5ç§’)
ä¸Šå‚³åˆ° Firebase Storage (116KB)
   â†“ (~1-2ç§’)
å»ºç«‹ Firestore è¨˜éŒ„
   â†“ (~1-3ç§’ - Cloud Function å†·å•Ÿå‹•)
Cloud Function è§¸ç™¼
   â†“ (~15-30ç§’ - ä¸»è¦ç“¶é ¸)
Zeabur API è™•ç†
  â”œâ”€ Whisper èªéŸ³è½‰æ–‡å­— (~10-20ç§’)
  â””â”€ GPT è§£æè¡Œç¨‹è³‡è¨Š (~5-10ç§’)
   â†“ (~1ç§’)
æ›´æ–° Firestore & å»ºç«‹è¡Œç¨‹
   â†“ (å³æ™‚)
Flutter ç›£è½åˆ°æ›´æ–°
```

**ç•¶å‰ç¸½æ™‚é–“ï¼šç´„ 20-45 ç§’**

---

## ğŸš€ å„ªåŒ–å»ºè­°ï¼ˆæŒ‰å„ªå…ˆç´šæ’åºï¼‰

### å„ªå…ˆç´š 1ï¼šæ¶æ§‹å„ªåŒ– â­â­â­â­â­

#### æ–¹æ¡ˆ Aï¼šç›´æ¥èª¿ç”¨ Zeabur APIï¼ˆæ¨è–¦ï¼‰
**æ•ˆæœï¼šæ¸›å°‘ 2-5 ç§’ï¼ˆçœå» Cloud Function å†·å•Ÿå‹•å’Œ Firestore å¾€è¿”ï¼‰**

**ç•¶å‰æ¶æ§‹ï¼ˆç•°æ­¥ï¼‰ï¼š**
```
Flutter â†’ Storage â†’ Firestore â†’ Cloud Function â†’ Zeabur API
         (ç­‰å¾…)      (ç›£è½)
```

**å„ªåŒ–å¾Œï¼ˆç›´æ¥èª¿ç”¨ï¼‰ï¼š**
```
Flutter â†’ Storage â†’ Zeabur APIï¼ˆç›´æ¥ï¼‰â†’ Firestore
         (ç­‰å¾…)                        (å„²å­˜çµæœ)
```

**å¯¦æ–½æ–¹å¼ï¼š**

ä¿®æ”¹ `flutter_app/lib/services/voice_service.dart`ï¼š

```dart
/// ç›´æ¥ä¸Šå‚³ä¸¦è™•ç†èªéŸ³ï¼ˆå„ªåŒ–ç‰ˆæœ¬ï¼‰
Future<String> uploadAndProcessVoiceDirectly(
  String? filePath,
  String userId, {
  Uint8List? audioBytes,
}) async {
  try {
    // 1. ä¸Šå‚³åˆ° Firebase Storageï¼ˆä¿æŒä¸è®Šï¼‰
    String audioUrl;
    
    if (kIsWeb) {
      if (audioBytes == null) {
        throw Exception('Web å¹³å°éœ€è¦æä¾›éŸ³æª”æ•¸æ“š');
      }
      audioUrl = await _firebaseService.uploadVoiceFileFromBytes(audioBytes, userId);
    } else {
      if (filePath == null) {
        throw Exception('ç§»å‹•å¹³å°éœ€è¦æä¾›æª”æ¡ˆè·¯å¾‘');
      }
      final file = File(filePath);
      final fileBytes = await file.readAsBytes();
      audioUrl = await _firebaseService.uploadVoiceFileFromBytesWithFormat(
        fileBytes, 
        userId,
        'audio/aac',
        'm4a',
      );
      
      // åˆªé™¤æœ¬åœ°æš«å­˜æª”æ¡ˆ
      await file.delete();
    }
    
    if (kDebugMode) {
      print('âœ… èªéŸ³æª”æ¡ˆå·²ä¸Šå‚³ï¼š$audioUrl');
    }
    
    // 2. ç›´æ¥èª¿ç”¨ Zeabur APIï¼ˆæ–°å¢ï¼‰
    final response = await http.post(
      Uri.parse('$kZeaburApiBaseUrl$kVoiceParseEndpoint'),
      headers: {'Content-Type': 'application/json'},
      body: json.encode({
        'audioUrl': audioUrl,
        'userId': userId,
      }),
    ).timeout(Duration(seconds: 60));
    
    if (response.statusCode != 200) {
      throw Exception('API è«‹æ±‚å¤±æ•—ï¼š${response.statusCode}');
    }
    
    final result = json.decode(utf8.decode(response.bodyBytes)) as Map<String, dynamic>;
    
    if (kDebugMode) {
      print('âœ… èªéŸ³è§£ææˆåŠŸï¼š${result['title']}');
    }
    
    // 3. ç«‹å³å»ºç«‹è¡Œç¨‹ï¼ˆä¸ç”¨ç­‰ Cloud Functionï¼‰
    final eventId = await _firebaseService.createEventFromVoiceResult(
      userId,
      result,
      audioUrl,
    );
    
    if (kDebugMode) {
      print('âœ… è¡Œç¨‹å»ºç«‹æˆåŠŸï¼š$eventId');
    }
    
    return eventId;
  } catch (e) {
    if (kDebugMode) {
      print('âŒ èªéŸ³è™•ç†å¤±æ•—ï¼š$e');
    }
    rethrow;
  }
}
```

**å„ªé»ï¼š**
- çœå» Cloud Function å†·å•Ÿå‹•æ™‚é–“ï¼ˆ1-3ç§’ï¼‰
- æ¸›å°‘ä¸€æ¬¡ Firestore å¾€è¿”ï¼ˆ1-2ç§’ï¼‰
- å¯¦æ™‚é€²åº¦å›é¥‹
- æ›´ç°¡å–®çš„éŒ¯èª¤è™•ç†

**ç¼ºé»ï¼š**
- Flutter éœ€è¦ç­‰å¾…æ•´å€‹éç¨‹å®Œæˆ
- éœ€è¦åœ¨ Firebase Service ä¸­æ·»åŠ  `createEventFromVoiceResult` æ–¹æ³•

---

### å„ªå…ˆç´š 2ï¼šéŸ³æª”å„ªåŒ– â­â­â­â­

#### é™ä½éŸ³æª”å¤§å°å’Œæ¡æ¨£ç‡
**æ•ˆæœï¼šæ¸›å°‘ 2-3 ç§’ä¸Šå‚³æ™‚é–“ï¼Œæ¸›å°‘ 3-5 ç§’ Whisper è™•ç†æ™‚é–“**

**ç•¶å‰è¨­å®šï¼ˆflutter_app/lib/services/voice_service.dartï¼‰ï¼š**
```dart
// ç§»å‹•å¹³å°
await _recorder.start(
  const RecordConfig(
    encoder: AudioEncoder.aacLc,
    bitRate: 128000,    // 128 kbpsï¼ˆé«˜éŸ³è³ªï¼‰
    sampleRate: 44100,  // 44.1 kHzï¼ˆCD éŸ³è³ªï¼‰
  ),
  path: _currentRecordingPath!,
);
```

**å„ªåŒ–å»ºè­°ï¼š**
```dart
// èªéŸ³è¾¨è­˜ä¸éœ€è¦é«˜éŸ³è³ª
await _recorder.start(
  const RecordConfig(
    encoder: AudioEncoder.aacLc,
    bitRate: 64000,     // 64 kbpsï¼ˆæ¸›å°‘ä¸€åŠï¼‰
    sampleRate: 16000,  // 16 kHzï¼ˆWhisper å®˜æ–¹æ¨è–¦ï¼‰
    numChannels: 1,     // å–®è²é“ï¼ˆç¢ºä¿è¨­å®šï¼‰
  ),
  path: _currentRecordingPath!,
);
```

**Web å¹³å°åŒæ¨£å„ªåŒ–ï¼š**
```dart
await _recorder.start(
  const RecordConfig(
    encoder: AudioEncoder.wav,
    sampleRate: 16000,  // é™ä½æ¡æ¨£ç‡
    numChannels: 1,     // å–®è²é“
  ),
  path: '',
);
```

**æ•ˆæœï¼š**
- æª”æ¡ˆå¤§å°æ¸›å°‘ 50-60%ï¼ˆ116KB â†’ 50-60KBï¼‰
- ä¸Šå‚³é€Ÿåº¦æå‡ 50%
- Whisper è™•ç†é€Ÿåº¦æå‡ 20-30%
- **ç¸½ç¯€çœæ™‚é–“ï¼š5-8 ç§’**

**æ³¨æ„äº‹é …ï¼š**
- 16kHz æ˜¯èªéŸ³è¾¨è­˜çš„æœ€ä½³å¹³è¡¡é»
- éŸ³è³ªå°äººè€³å¯èƒ½ç¨é™ä½ï¼Œä½†å° AI è¾¨è­˜ç„¡å½±éŸ¿
- Whisper æ¨¡å‹é‡å° 16kHz å„ªåŒ–

---

### å„ªå…ˆç´š 3ï¼šUI/UX å„ªåŒ– â­â­â­â­

#### æ·»åŠ è™•ç†é€²åº¦æç¤º
**æ•ˆæœï¼šæ”¹å–„ç”¨æˆ¶é«”é©—ï¼Œæ¸›å°‘ç­‰å¾…ç„¦æ…®ï¼ˆä¸æ¸›å°‘å¯¦éš›æ™‚é–“ä½†å¤§å¹…æå‡æ„ŸçŸ¥é€Ÿåº¦ï¼‰**

**å¯¦æ–½æ­¥é©Ÿï¼š**

**1. ä¿®æ”¹ `flutter_app/lib/providers/voice_provider.dart`ï¼š**

```dart
/// è™•ç†éšæ®µæšèˆ‰
enum ProcessingStage {
  uploading,      // ä¸Šå‚³ä¸­ (0-20%)
  transcribing,   // è½‰éŒ„ä¸­ (20-70%)
  analyzing,      // åˆ†æä¸­ (70-90%)
  creating,       // å»ºç«‹è¡Œç¨‹ä¸­ (90-100%)
  completed,      // å®Œæˆ
}

/// èªéŸ³æ§åˆ¶å™¨ State
class VoiceState {
  final bool isRecording;
  final bool isProcessing;
  final String? errorMessage;
  final String? successMessage;
  final String? currentRecordId;
  final int recordingDuration;
  
  // æ–°å¢è™•ç†éšæ®µç›¸é—œæ¬„ä½
  final ProcessingStage? currentStage;
  final double progress; // 0.0 - 1.0
  
  const VoiceState({
    this.isRecording = false,
    this.isProcessing = false,
    this.errorMessage,
    this.successMessage,
    this.currentRecordId,
    this.recordingDuration = 0,
    this.currentStage,
    this.progress = 0.0,
  });
  
  /// å–å¾—ç•¶å‰éšæ®µçš„è¨Šæ¯
  String get stageMessage {
    switch (currentStage) {
      case ProcessingStage.uploading:
        return 'æ­£åœ¨ä¸Šå‚³èªéŸ³æª”æ¡ˆ...';
      case ProcessingStage.transcribing:
        return 'æ­£åœ¨è½‰éŒ„èªéŸ³å…§å®¹...';
      case ProcessingStage.analyzing:
        return 'æ­£åœ¨åˆ†æè¡Œç¨‹è³‡è¨Š...';
      case ProcessingStage.creating:
        return 'æ­£åœ¨å»ºç«‹è¡Œç¨‹...';
      case ProcessingStage.completed:
        return 'è™•ç†å®Œæˆï¼';
      default:
        return 'è™•ç†ä¸­...';
    }
  }
  
  /// å–å¾—é ä¼°å‰©é¤˜æ™‚é–“ï¼ˆç§’ï¼‰
  int get estimatedRemainingSeconds {
    if (currentStage == null) return 0;
    
    // æ ¹æ“šéšæ®µé ä¼°å‰©é¤˜æ™‚é–“
    switch (currentStage!) {
      case ProcessingStage.uploading:
        return 20; // é‚„éœ€è¦ç´„ 20 ç§’
      case ProcessingStage.transcribing:
        return 15; // é‚„éœ€è¦ç´„ 15 ç§’
      case ProcessingStage.analyzing:
        return 5;  // é‚„éœ€è¦ç´„ 5 ç§’
      case ProcessingStage.creating:
        return 2;  // é‚„éœ€è¦ç´„ 2 ç§’
      case ProcessingStage.completed:
        return 0;
    }
  }
  
  VoiceState copyWith({
    bool? isRecording,
    bool? isProcessing,
    String? errorMessage,
    String? successMessage,
    String? currentRecordId,
    int? recordingDuration,
    ProcessingStage? currentStage,
    double? progress,
    bool clearMessages = false,
  }) {
    return VoiceState(
      isRecording: isRecording ?? this.isRecording,
      isProcessing: isProcessing ?? this.isProcessing,
      errorMessage: clearMessages ? null : (errorMessage ?? this.errorMessage),
      successMessage: clearMessages ? null : (successMessage ?? this.successMessage),
      currentRecordId: currentRecordId ?? this.currentRecordId,
      recordingDuration: recordingDuration ?? this.recordingDuration,
      currentStage: currentStage ?? this.currentStage,
      progress: progress ?? this.progress,
    );
  }
}
```

**2. åœ¨è™•ç†éç¨‹ä¸­æ›´æ–°éšæ®µï¼š**

```dart
Future<void> _processVoiceData({String? filePath, Uint8List? audioBytes}) async {
  // ... å‰é¢ä»£ç¢¼ä¿æŒä¸è®Š ...
  
  state = state.copyWith(
    isProcessing: true,
    currentStage: ProcessingStage.uploading,
    progress: 0.1,
  );

  try {
    // ä¸Šå‚³èªéŸ³æª”æ¡ˆ
    final recordId = await _voiceService.uploadAndProcessVoice(
      filePath,
      userId,
      audioBytes: audioBytes,
    );
    
    // æ›´æ–°ç‚ºè½‰éŒ„éšæ®µ
    state = state.copyWith(
      currentStage: ProcessingStage.transcribing,
      progress: 0.3,
      currentRecordId: recordId,
    );

    // ç›£è½è™•ç†çµæœï¼ˆæ·»åŠ æ¨¡æ“¬é€²åº¦ï¼‰
    Timer.periodic(Duration(seconds: 2), (timer) {
      if (state.currentStage == ProcessingStage.transcribing && state.progress < 0.7) {
        state = state.copyWith(progress: state.progress + 0.1);
      } else if (state.currentStage == ProcessingStage.analyzing && state.progress < 0.9) {
        state = state.copyWith(progress: state.progress + 0.05);
      }
      
      if (!state.isProcessing) {
        timer.cancel();
      }
    });
    
    // ... å¾ŒçºŒè™•ç† ...
  } catch (e) {
    // éŒ¯èª¤è™•ç†
  }
}
```

**3. åœ¨ UI ä¸­é¡¯ç¤ºé€²åº¦ï¼ˆvoice_input_screen.dartï¼‰ï¼š**

```dart
// è™•ç†ä¸­ç‹€æ…‹çš„ UI
if (voiceState.isProcessing) {
  return Container(
    padding: EdgeInsets.all(24),
    child: Column(
      mainAxisSize: MainAxisSize.min,
      children: [
        // åœ“å½¢é€²åº¦æŒ‡ç¤ºå™¨
        Stack(
          alignment: Alignment.center,
          children: [
            SizedBox(
              width: 100,
              height: 100,
              child: CircularProgressIndicator(
                value: voiceState.progress,
                strokeWidth: 8,
                backgroundColor: Colors.grey[300],
                valueColor: AlwaysStoppedAnimation<Color>(
                  Color(kPrimaryColorValue),
                ),
              ),
            ),
            Text(
              '${(voiceState.progress * 100).toInt()}%',
              style: TextStyle(
                fontSize: 24,
                fontWeight: FontWeight.bold,
              ),
            ),
          ],
        ),
        
        SizedBox(height: 24),
        
        // éšæ®µè¨Šæ¯
        Text(
          voiceState.stageMessage,
          style: TextStyle(
            fontSize: 18,
            fontWeight: FontWeight.w500,
          ),
        ),
        
        SizedBox(height: 8),
        
        // é ä¼°å‰©é¤˜æ™‚é–“
        if (voiceState.estimatedRemainingSeconds > 0)
          Text(
            'é è¨ˆé‚„éœ€ ${voiceState.estimatedRemainingSeconds} ç§’',
            style: TextStyle(
              fontSize: 14,
              color: Colors.grey[600],
            ),
          ),
        
        SizedBox(height: 24),
        
        // å¯é¸ï¼šå–æ¶ˆæŒ‰éˆ•
        TextButton(
          onPressed: () {
            // å–æ¶ˆè™•ç†é‚è¼¯
            Navigator.pop(context);
          },
          child: Text('è¿”å›æ—¥æ›†'),
        ),
      ],
    ),
  );
}
```

**æ•ˆæœï¼š**
- ç”¨æˆ¶æ¸…æ¥šäº†è§£ç•¶å‰é€²åº¦
- æ¸›å°‘ç„¦æ…®æ„Ÿ
- æä¾›é ä¼°æ™‚é–“
- å…è¨±ä¸­é€”è¿”å›

---

### å„ªå…ˆç´š 4ï¼šZeabur API å„ªåŒ– â­â­â­

#### å¾Œç«¯ä¸¦è¡Œè™•ç†
**æ•ˆæœï¼šæ¸›å°‘ 5-10 ç§’è™•ç†æ™‚é–“**

**ç•¶å‰æµç¨‹ï¼ˆä¸²è¡Œï¼‰ï¼š**
```python
# zeabur_api/app/routes/voice.py
async def parse_voice(request: VoiceParseRequest):
    # 1. ä¸‹è¼‰éŸ³æª” (2ç§’)
    audio_bytes = await download_audio(request.audioUrl)
    
    # 2. Whisper è½‰éŒ„ (15ç§’)
    transcription = await whisper_service.transcribe(audio_bytes)
    
    # 3. GPT è§£æ (8ç§’)
    result = await gpt_service.parse(transcription)
    
    # ç¸½è¨ˆï¼š25ç§’
    return result
```

**å„ªåŒ–å»ºè­° 1ï¼šé è™•ç†éŸ³æª”ï¼ˆä¸¦è¡Œï¼‰**
```python
import asyncio

async def parse_voice_optimized(request: VoiceParseRequest):
    # ä¸¦è¡Œï¼šä¸‹è¼‰ + é è™•ç†
    download_task = asyncio.create_task(download_audio(request.audioUrl))
    
    # ç­‰å¾…ä¸‹è¼‰å®Œæˆ
    audio_bytes = await download_task
    
    # ä¸¦è¡Œï¼šéŸ³æª”é è™•ç† + Whisper è½‰éŒ„
    preprocess_task = asyncio.create_task(preprocess_audio(audio_bytes))
    transcribe_task = asyncio.create_task(whisper_service.transcribe(audio_bytes))
    
    # ç­‰å¾…è½‰éŒ„å®Œæˆ
    transcription = await transcribe_task
    
    # GPT è§£æï¼ˆå¯ä»¥åœ¨è½‰éŒ„æ™‚å°±é–‹å§‹éƒ¨åˆ†è§£æï¼‰
    result = await gpt_service.parse(transcription)
    
    return result
```

**å„ªåŒ–å»ºè­° 2ï¼šä¸²æµè™•ç†ï¼ˆé€²éšï¼‰**
```python
async def parse_voice_streaming(request: VoiceParseRequest):
    """
    ä¸²æµæ¨¡å¼ï¼šé‚Šè½‰éŒ„é‚Šåˆ†æ
    éœ€è¦ Whisper API æ”¯æ´ä¸²æµè¼¸å‡º
    """
    audio_bytes = await download_audio(request.audioUrl)
    
    partial_transcription = ""
    partial_result = None
    
    # Whisper ä¸²æµè½‰éŒ„
    async for chunk in whisper_service.transcribe_stream(audio_bytes):
        partial_transcription += chunk
        
        # å¦‚æœç´¯ç©è¶³å¤ æ–‡å­—ï¼Œé–‹å§‹éƒ¨åˆ†è§£æ
        if len(partial_transcription) > 50:
            # éé˜»å¡å¼è§£æ
            partial_result = await gpt_service.parse_partial(partial_transcription)
    
    # æœ€çµ‚ä¿®æ­£å’Œå®Œå–„
    final_result = await gpt_service.finalize(partial_result, partial_transcription)
    
    return final_result
```

**å¯¦æ–½æ³¨æ„äº‹é …ï¼š**
- éœ€è¦æª¢æŸ¥ Whisper API æ˜¯å¦æ”¯æ´ä¸²æµæ¨¡å¼
- éœ€è¦è™•ç†éƒ¨åˆ†çµæœçš„åˆä½µé‚è¼¯
- å¯èƒ½éœ€è¦èª¿æ•´ GPT prompt ä»¥æ”¯æ´éƒ¨åˆ†æ–‡å­—è§£æ

---

### å„ªå…ˆç´š 5ï¼šéŸ³æª”é è™•ç† â­â­

#### æ·»åŠ éŸ³æª”å„ªåŒ–è™•ç†
**æ•ˆæœï¼šæå‡ Whisper è¾¨è­˜é€Ÿåº¦ 10-20%ï¼Œæº–ç¢ºåº¦æå‡**

**åœ¨ Zeabur API ç«¯æ·»åŠ é è™•ç†ï¼š**

```python
# zeabur_api/app/services/audio_processor.py
import numpy as np
from pydub import AudioSegment
from pydub.effects import normalize
import io

class AudioProcessor:
    """éŸ³æª”é è™•ç†æœå‹™"""
    
    @staticmethod
    def preprocess_for_whisper(audio_bytes: bytes) -> bytes:
        """
        å„ªåŒ–éŸ³æª”ä»¥æå‡ Whisper è¾¨è­˜æ•ˆæœ
        
        è™•ç†æ­¥é©Ÿï¼š
        1. è½‰æ›ç‚º 16kHz å–®è²é“
        2. æ¨™æº–åŒ–éŸ³é‡
        3. é™å™ªï¼ˆç°¡å–®ï¼‰
        4. è£å‰ªé ­å°¾éœéŸ³
        """
        # 1. è¼‰å…¥éŸ³æª”
        audio = AudioSegment.from_file(io.BytesIO(audio_bytes))
        
        # 2. è½‰æ›ç‚º Whisper æœ€ä½³æ ¼å¼
        audio = audio.set_channels(1)  # å–®è²é“
        audio = audio.set_frame_rate(16000)  # 16kHz
        
        # 3. æ¨™æº–åŒ–éŸ³é‡
        audio = normalize(audio)
        
        # 4. è£å‰ªé ­å°¾éœéŸ³ï¼ˆè¶…é 1 ç§’çš„éœéŸ³ï¼‰
        audio = AudioProcessor._trim_silence(audio, silence_thresh=-40)
        
        # 5. å°å‡ºç‚º WAVï¼ˆWhisper æœ€ä½³æ ¼å¼ï¼‰
        buffer = io.BytesIO()
        audio.export(buffer, format='wav')
        
        return buffer.getvalue()
    
    @staticmethod
    def _trim_silence(audio: AudioSegment, silence_thresh: int = -40) -> AudioSegment:
        """è£å‰ªé ­å°¾éœéŸ³"""
        def detect_leading_silence(sound, silence_threshold=-50.0, chunk_size=10):
            trim_ms = 0
            assert chunk_size > 0
            while sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold and trim_ms < len(sound):
                trim_ms += chunk_size
            return trim_ms
        
        start_trim = detect_leading_silence(audio, silence_thresh)
        end_trim = detect_leading_silence(audio.reverse(), silence_thresh)
        
        duration = len(audio)
        trimmed = audio[start_trim:duration-end_trim]
        
        return trimmed
```

**åœ¨ voice route ä¸­ä½¿ç”¨ï¼š**

```python
# zeabur_api/app/routes/voice.py
from ..services.audio_processor import AudioProcessor

async def parse_voice(request: VoiceParseRequest):
    # ä¸‹è¼‰éŸ³æª”
    audio_bytes = await download_audio(request.audioUrl)
    
    # é è™•ç†éŸ³æª”
    processed_audio = AudioProcessor.preprocess_for_whisper(audio_bytes)
    
    # Whisper è½‰éŒ„ï¼ˆä½¿ç”¨è™•ç†å¾Œçš„éŸ³æª”ï¼‰
    transcription = await whisper_service.transcribe(processed_audio)
    
    # GPT è§£æ
    result = await gpt_service.parse(transcription)
    
    return result
```

**éœ€è¦å®‰è£çš„å¥—ä»¶ï¼š**
```bash
# requirements.txt
pydub==0.25.1
numpy==1.24.3
```

---

## ğŸ“ˆ å„ªåŒ–æ•ˆæœé ä¼°è¡¨

| å„ªåŒ–é …ç›® | æ™‚é–“ç¯€çœ | å¯¦æ–½é›£åº¦ | å„ªå…ˆç´š | é ä¼°å·¥æ™‚ |
|---------|---------|---------|--------|---------|
| ç›´æ¥èª¿ç”¨ API | 2-5ç§’ | ä¸­ | â­â­â­â­â­ | 1-2å°æ™‚ |
| é™ä½æ¡æ¨£ç‡/ä½å…ƒç‡ | 5-8ç§’ | ä½ | â­â­â­â­ | 5åˆ†é˜ |
| UI é€²åº¦æç¤º | 0ç§’ï¼ˆé«”é©—æå‡ï¼‰ | ä½ | â­â­â­â­ | 30åˆ†é˜ |
| å¾Œç«¯ä¸¦è¡Œè™•ç† | 5-10ç§’ | é«˜ | â­â­â­ | 3-4å°æ™‚ |
| éŸ³æª”é è™•ç† | 2-4ç§’ | ä¸­ | â­â­ | 1-2å°æ™‚ |

**ç´¯ç©å„ªåŒ–æ•ˆæœï¼š**
- **ç¬¬ä¸€éšæ®µ**ï¼ˆéŸ³è³ª + UIï¼‰ï¼š5-8ç§’ + é«”é©—å¤§å¹…æå‡
- **ç¬¬äºŒéšæ®µ**ï¼ˆç›´æ¥èª¿ç”¨ï¼‰ï¼šå†æ¸›å°‘ 2-5ç§’
- **ç¬¬ä¸‰éšæ®µ**ï¼ˆå¾Œç«¯å„ªåŒ–ï¼‰ï¼šå†æ¸›å°‘ 7-14ç§’

**ç¸½è¨ˆï¼šå¾ 25-40ç§’ â†’ 8-15ç§’ï¼ˆæ¸›å°‘ç´„ 60-70%ï¼‰**

---

## ğŸ¯ å»ºè­°å¯¦æ–½é †åº

### ç¬¬ä¸€éšæ®µï¼ˆå¿«é€Ÿè¦‹æ•ˆï¼‰âš¡
**æ™‚é–“ï¼š40åˆ†é˜ï¼Œç«‹å³è¦‹æ•ˆ**

1. **é™ä½éŒ„éŸ³éŸ³è³ªè¨­å®š**ï¼ˆ5åˆ†é˜ï¼‰
   - ä¿®æ”¹ `voice_service.dart` ä¸­çš„éŒ„éŸ³é…ç½®
   - æ¸¬è©¦éŸ³è³ªæ˜¯å¦å¯æ¥å—
   - é æœŸæ•ˆæœï¼šæ¸›å°‘ 5-8ç§’

2. **æ·»åŠ  UI é€²åº¦æç¤º**ï¼ˆ30åˆ†é˜ï¼‰
   - ä¿®æ”¹ `VoiceState` æ·»åŠ è™•ç†éšæ®µ
   - æ›´æ–° UI é¡¯ç¤ºé€²åº¦
   - é æœŸæ•ˆæœï¼šé«”é©—å¤§å¹…æå‡

3. **æ¸¬è©¦èˆ‡èª¿å„ª**ï¼ˆ5åˆ†é˜ï¼‰
   - å®Œæ•´æµç¨‹æ¸¬è©¦
   - è¨˜éŒ„å¯¦éš›è€—æ™‚

### ç¬¬äºŒéšæ®µï¼ˆä¸­æœŸå„ªåŒ–ï¼‰ğŸš€
**æ™‚é–“ï¼š1-2å°æ™‚ï¼Œæ¶æ§‹å„ªåŒ–**

4. **ç›´æ¥èª¿ç”¨ Zeabur API**ï¼ˆ1-2å°æ™‚ï¼‰
   - é‡æ§‹ `uploadAndProcessVoice` æ–¹æ³•
   - æ·»åŠ  Firebase Service è¼”åŠ©æ–¹æ³•
   - æ›´æ–°éŒ¯èª¤è™•ç†é‚è¼¯
   - é æœŸæ•ˆæœï¼šæ¸›å°‘ 2-5ç§’

5. **å®Œæ•´æ¸¬è©¦**ï¼ˆ30åˆ†é˜ï¼‰
   - å„å¹³å°æ¸¬è©¦ï¼ˆWebã€Androidï¼‰
   - éŒ¯èª¤å ´æ™¯æ¸¬è©¦
   - æ€§èƒ½å°æ¯”æ¸¬è©¦

### ç¬¬ä¸‰éšæ®µï¼ˆæ·±åº¦å„ªåŒ–ï¼‰ğŸ”¬
**æ™‚é–“ï¼š4-6å°æ™‚ï¼Œéœ€è¦å¾Œç«¯é…åˆ**

6. **å¾Œç«¯ä¸¦è¡Œè™•ç†**ï¼ˆ2-3å°æ™‚ï¼‰
   - é‡æ§‹ Zeabur API è·¯ç”±
   - å¯¦æ–½éåŒæ­¥ä¸¦è¡Œè™•ç†
   - æ¸¬è©¦ç©©å®šæ€§
   - é æœŸæ•ˆæœï¼šæ¸›å°‘ 5-10ç§’

7. **éŸ³æª”é è™•ç†**ï¼ˆ2å°æ™‚ï¼‰
   - æ·»åŠ éŸ³è¨Šè™•ç†åº«
   - å¯¦æ–½é è™•ç†é‚è¼¯
   - æ¸¬è©¦è¾¨è­˜æº–ç¢ºåº¦
   - é æœŸæ•ˆæœï¼šæ¸›å°‘ 2-4ç§’ï¼Œæå‡æº–ç¢ºåº¦

8. **å…¨é¢æ¸¬è©¦èˆ‡å„ªåŒ–**ï¼ˆ1å°æ™‚ï¼‰
   - ç«¯åˆ°ç«¯æ¸¬è©¦
   - æ€§èƒ½ç›£æ§
   - å•é¡Œä¿®å¾©

---

## ğŸ’¡ é¡å¤–å»ºè­°

### 1. æ·»åŠ è¶…æ™‚è™•ç†
```dart
// åœ¨ voice_provider.dart ä¸­æ·»åŠ 
Future<void> _processVoiceData({String? filePath, Uint8List? audioBytes}) async {
  // ... ç¾æœ‰ä»£ç¢¼ ...
  
  // è¨­å®šè¶…æ™‚
  final timeoutDuration = Duration(seconds: 45);
  
  try {
    await Future.any([
      _actualProcessing(filePath, audioBytes),
      Future.delayed(timeoutDuration).then((_) => throw TimeoutException('è™•ç†è¶…æ™‚')),
    ]);
  } on TimeoutException {
    state = state.copyWith(
      isProcessing: false,
      errorMessage: 'è™•ç†æ™‚é–“éé•·ï¼Œè«‹ç¨å¾Œé‡è©¦',
    );
  }
}
```

### 2. æ·»åŠ èƒŒæ™¯è™•ç†æ¨¡å¼
å…è¨±ç”¨æˆ¶åœ¨è™•ç†èªéŸ³æ™‚è¿”å›æ—¥æ›†ï¼Œè™•ç†å®Œæˆå¾Œç™¼é€é€šçŸ¥ï¼š

```dart
// åœ¨ voice_input_screen.dart ä¸­
if (voiceState.isProcessing) {
  // ... é¡¯ç¤ºé€²åº¦ UI ...
  
  // æ·»åŠ ã€Œè¿”å›æ—¥æ›†ã€æŒ‰éˆ•
  TextButton.icon(
    onPressed: () {
      // é¡¯ç¤ºæç¤º
      showDialog(
        context: context,
        builder: (_) => AlertDialog(
          title: Text('ç¹¼çºŒè™•ç†'),
          content: Text('èªéŸ³è™•ç†å°‡åœ¨èƒŒæ™¯ç¹¼çºŒé€²è¡Œï¼Œå®Œæˆå¾Œæœƒé€šçŸ¥æ‚¨ã€‚'),
          actions: [
            TextButton(
              onPressed: () {
                Navigator.pop(context); // é—œé–‰å°è©±æ¡†
                Navigator.pop(context); // è¿”å›æ—¥æ›†
              },
              child: Text('ç¢ºå®š'),
            ),
          ],
        ),
      );
    },
    icon: Icon(Icons.arrow_back),
    label: Text('è¿”å›æ—¥æ›†'),
  ),
}
```

### 3. æ·»åŠ è™•ç†æˆåŠŸçš„å‹•ç•«åé¥‹
```dart
// è™•ç†å®Œæˆæ™‚é¡¯ç¤ºæ…¶ç¥å‹•ç•«
if (voiceState.successMessage != null) {
  return Column(
    mainAxisAlignment: MainAxisAlignment.center,
    children: [
      // æˆåŠŸåœ–ç¤ºï¼ˆå¯ä½¿ç”¨ Lottie å‹•ç•«ï¼‰
      Icon(
        Icons.check_circle,
        size: 80,
        color: Color(kSuccessColorValue),
      ),
      SizedBox(height: 16),
      Text(
        voiceState.successMessage!,
        style: TextStyle(
          fontSize: 18,
          fontWeight: FontWeight.w500,
        ),
      ),
      SizedBox(height: 24),
      ElevatedButton(
        onPressed: () => Navigator.pop(context),
        child: Text('æŸ¥çœ‹è¡Œç¨‹'),
      ),
    ],
  );
}
```

### 4. æ·»åŠ æ•ˆèƒ½ç›£æ§
```dart
// åœ¨ voice_service.dart ä¸­æ·»åŠ è¨ˆæ™‚
Future<String> uploadAndProcessVoice(...) async {
  final startTime = DateTime.now();
  
  try {
    // ... è™•ç†é‚è¼¯ ...
    
    final duration = DateTime.now().difference(startTime);
    
    if (kDebugMode) {
      print('â±ï¸ ç¸½è™•ç†æ™‚é–“ï¼š${duration.inSeconds} ç§’');
    }
    
    // å¯é¸ï¼šä¸Šå‚³åˆ° Firebase Analytics
    // await FirebaseAnalytics.instance.logEvent(
    //   name: 'voice_processing_time',
    //   parameters: {'duration_seconds': duration.inSeconds},
    // );
    
    return recordId;
  } catch (e) {
    final duration = DateTime.now().difference(startTime);
    print('âŒ è™•ç†å¤±æ•—ï¼Œè€—æ™‚ï¼š${duration.inSeconds} ç§’');
    rethrow;
  }
}
```

---

## ğŸ§ª æ¸¬è©¦æª¢æŸ¥æ¸…å–®

å„ªåŒ–å¾Œéœ€è¦æ¸¬è©¦çš„é …ç›®ï¼š

### åŠŸèƒ½æ¸¬è©¦
- [ ] çŸ­èªéŸ³ï¼ˆ5ç§’å…§ï¼‰è™•ç†æ­£å¸¸
- [ ] ä¸­ç­‰èªéŸ³ï¼ˆ10-30ç§’ï¼‰è™•ç†æ­£å¸¸
- [ ] é•·èªéŸ³ï¼ˆ30-60ç§’ï¼‰è™•ç†æ­£å¸¸
- [ ] éŸ³è³ªå¯æ¥å—ï¼ˆäººè€³æ¸¬è©¦ï¼‰
- [ ] è¾¨è­˜æº–ç¢ºåº¦ç„¡ä¸‹é™

### å¹³å°æ¸¬è©¦
- [ ] Android å¹³å°æ­£å¸¸é‹ä½œ
- [ ] iOS å¹³å°æ­£å¸¸é‹ä½œï¼ˆå¦‚æœ‰ï¼‰
- [ ] Web å¹³å°æ­£å¸¸é‹ä½œ

### éŒ¯èª¤å ´æ™¯æ¸¬è©¦
- [ ] ç¶²è·¯ä¸­æ–·æ™‚çš„éŒ¯èª¤è™•ç†
- [ ] API è¶…æ™‚æ™‚çš„éŒ¯èª¤è™•ç†
- [ ] éŸ³æª”ä¸Šå‚³å¤±æ•—çš„éŒ¯èª¤è™•ç†
- [ ] è¾¨è­˜å¤±æ•—çš„éŒ¯èª¤è™•ç†

### æ€§èƒ½æ¸¬è©¦
- [ ] è¨˜éŒ„å„ªåŒ–å‰çš„å¹³å‡è™•ç†æ™‚é–“
- [ ] è¨˜éŒ„å„ªåŒ–å¾Œçš„å¹³å‡è™•ç†æ™‚é–“
- [ ] è¨ˆç®—å¯¦éš›æå‡ç™¾åˆ†æ¯”
- [ ] æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³

### UX æ¸¬è©¦
- [ ] é€²åº¦é¡¯ç¤ºæµæš¢
- [ ] é ä¼°æ™‚é–“åˆç†
- [ ] éŒ¯èª¤è¨Šæ¯æ¸…æ™°
- [ ] å¯ä»¥ä¸­é€”å–æ¶ˆ

---

## ğŸ“š åƒè€ƒè³‡æº

### Whisper æœ€ä½³å¯¦è¸
- [OpenAI Whisper å®˜æ–¹æ–‡æª”](https://platform.openai.com/docs/guides/speech-to-text)
- æ¨è–¦éŸ³è¨Šæ ¼å¼ï¼š16kHz, mono, WAV/M4A
- æœ€å¤§æª”æ¡ˆå¤§å°ï¼š25MB
- æœ€é•·æ™‚é•·ï¼š25åˆ†é˜

### Flutter éŸ³è¨Šè™•ç†
- [record å¥—ä»¶æ–‡æª”](https://pub.dev/packages/record)
- [path_provider å¥—ä»¶](https://pub.dev/packages/path_provider)

### Firebase æœ€ä½³å¯¦è¸
- [Cloud Functions æ€§èƒ½å„ªåŒ–](https://firebase.google.com/docs/functions/tips)
- [Firestore æ‰¹æ¬¡å¯«å…¥](https://firebase.google.com/docs/firestore/manage-data/transactions)

---

## ğŸ“Š å„ªåŒ–å‰å¾Œå°æ¯”ï¼ˆé æœŸï¼‰

| æŒ‡æ¨™ | å„ªåŒ–å‰ | ç¬¬ä¸€éšæ®µ | ç¬¬äºŒéšæ®µ | ç¬¬ä¸‰éšæ®µ |
|------|--------|---------|---------|---------|
| å¹³å‡è™•ç†æ™‚é–“ | 25-40ç§’ | 18-30ç§’ | 12-22ç§’ | 8-15ç§’ |
| éŸ³æª”å¤§å° | 116KB | 50-60KB | 50-60KB | 40-50KB |
| ç”¨æˆ¶æ»¿æ„åº¦ | â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| å¯¦æ–½æˆæœ¬ | - | ä½ | ä¸­ | é«˜ |

---

## ğŸ¯ çµè«–

**å»ºè­°å¯¦æ–½ç­–ç•¥ï¼š**

1. **ç«‹å³å¯¦æ–½**ï¼ˆä»Šå¤©å®Œæˆï¼‰ï¼š
   - âœ… é™ä½éŒ„éŸ³éŸ³è³ªï¼ˆ5åˆ†é˜ï¼‰
   - âœ… æ·»åŠ  UI é€²åº¦æç¤ºï¼ˆ30åˆ†é˜ï¼‰
   - é æœŸæ•ˆæœï¼šé«”é©—ç«‹å³æ”¹å–„ï¼Œæ™‚é–“æ¸›å°‘ 20-30%

2. **æœ¬é€±å®Œæˆ**ï¼š
   - âœ… ç›´æ¥èª¿ç”¨ Zeabur APIï¼ˆ1-2å°æ™‚ï¼‰
   - é æœŸæ•ˆæœï¼šç¸½æ™‚é–“æ¸›å°‘ 50%

3. **å¾ŒçºŒå„ªåŒ–**ï¼ˆæ™‚é–“å……è£•æ™‚ï¼‰ï¼š
   - â° å¾Œç«¯ä¸¦è¡Œè™•ç†
   - â° éŸ³æª”é è™•ç†
   - é æœŸæ•ˆæœï¼šç¸½æ™‚é–“æ¸›å°‘ 60-70%

**æ ¸å¿ƒç›®æ¨™ï¼š** å°‡è™•ç†æ™‚é–“å¾ 30ç§’ é™ä½åˆ° 15ç§’ä»¥å…§ï¼Œä¸¦æä¾›æ¸…æ™°çš„é€²åº¦åé¥‹ã€‚

---

**æ–‡æª”ç‰ˆæœ¬ï¼š** v1.0  
**å»ºç«‹æ—¥æœŸï¼š** 2025-12-13  
**ä½œè€…ï¼š** AI Calendar Team  
**æœ€å¾Œæ›´æ–°ï¼š** 2025-12-13

